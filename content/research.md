---
id: research
filename: research.py
icon: microscope
pyModule: research_lab
lang: python
---

# Research Interests

**ãƒã‚¤ãƒ‘ãƒ¼ã‚°ãƒ©ãƒ•è¡¨ç¾å­¦ç¿’ (Hypergraph Representation Learning)** ã¨ **å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ« (LLM)** ã®èåˆã«å–ã‚Šçµ„ã‚“ã§ã„ã¾ã™ã€‚

---

## ğŸ”¬ Core Concept: Knowledge Integration

ç”Ÿç‰©åŒ»å­¦åˆ†é‡ã®ã‚ˆã†ãªè¤‡é›‘ãªå°‚é–€çŸ¥è­˜ï¼ˆãƒ†ã‚­ã‚¹ãƒˆã€åŒ–å­¦æ§‹é€ ã€æ•°å€¤ãƒ‡ãƒ¼ã‚¿ï¼‰ã‚’ã€æƒ…å ±ã®æå¤±ãªãLLMã«çµ±åˆã™ã‚‹æ‰‹æ³•ã‚’ç ”ç©¶ã—ã¦ã„ã¾ã™ã€‚

> **èª²é¡Œ:** å¾“æ¥ã®RAGç­‰ã¯å…¨ã¦ã®æƒ…å ±ã‚’ãƒ†ã‚­ã‚¹ãƒˆåŒ–ã™ã‚‹ãŸã‚ã€æ§‹é€ æƒ…å ±ã‚„æ•°å€¤ç²¾åº¦ãŒå¤±ã‚ã‚Œã‚‹ã€‚
> **ææ¡ˆ:** ãƒã‚¤ãƒ‘ãƒ¼ã‚°ãƒ©ãƒ•ã‚’çŸ¥è­˜è¡¨ç¾åŸºç›¤ã¨ã—ã€LLMã®å†…éƒ¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«ç›´æ¥çµ±åˆã™ã‚‹ã€‚

## ğŸ§ª Implementation Preview

ç ”ç©¶ã§ä½¿ç”¨ã—ã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«æ§‹é€ ã®æ¦‚å¿µã‚³ãƒ¼ãƒ‰ã§ã™ã€‚

\`\`\`python
import torch
from torch_geometric.nn import HypergraphConv

class NishideModel(torch.nn.Module):
    """
    Multimodal Hypergraph Knowledge Integrator
    """
    def __init__(self, hidden_dim=768):
        super().__init__()
        # LLM Backbone
        self.llm = AutoModel.from_pretrained("bert-base-uncased")
        
        # Structural Encoder (Hypergraph)
        # æ¬¡æ•°ãƒã‚¤ã‚¢ã‚¹ã‚’è§£æ¶ˆã™ã‚‹ç‹¬è‡ªã®æ­£è¦åŒ–é …ã‚’é©ç”¨
        self.gnn = HypergraphConv(in_channels=hidden_dim, 
                                out_channels=hidden_dim)

    def forward(self, text, chem_graph):
        # ãƒ†ã‚­ã‚¹ãƒˆã¨æ§‹é€ æƒ…å ±ã®èåˆ
        text_emb = self.llm(text).last_hidden_state
        struct_emb = self.gnn(chem_graph.x, chem_graph.edge_index)
        
        return torch.cat([text_emb, struct_emb], dim=-1)
\`\`\`

## ğŸ“š Publications
- **è¨€èªå‡¦ç†å­¦ä¼š 2025**: ç•°ç¨®å±æ€§ã®å†…å®¹çš„ç‰¹å¾´ã‚’ãƒã‚¤ãƒ‘ãƒ¼ã‚°ãƒ©ãƒ•ã«ã‚ˆã‚Šçµ±åˆã™ã‚‹ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£è¡¨ç¾å­¦ç¿’
